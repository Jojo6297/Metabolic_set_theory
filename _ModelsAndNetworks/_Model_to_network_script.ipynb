{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cobra\n",
    "from cobra.io import load_model, read_sbml_model\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import os\n",
    "import glob\n",
    "import natsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\sainz\\\\OneDrive\\\\Desktop\\\\Hamburg 3.2\\\\_MetabolicSetTheory_repo\\\\_ModelsAndNetworks\\\\models\\\\Actinomyces_odontolyticus_ATCC_17982.xml',\n",
       " 'c:\\\\Users\\\\sainz\\\\OneDrive\\\\Desktop\\\\Hamburg 3.2\\\\_MetabolicSetTheory_repo\\\\_ModelsAndNetworks\\\\models\\\\Alistipes_putredinis_DSM_17216.xml',\n",
       " 'c:\\\\Users\\\\sainz\\\\OneDrive\\\\Desktop\\\\Hamburg 3.2\\\\_MetabolicSetTheory_repo\\\\_ModelsAndNetworks\\\\models\\\\Anaerococcus_hydrogenalis_DSM_7454.xml',\n",
       " 'c:\\\\Users\\\\sainz\\\\OneDrive\\\\Desktop\\\\Hamburg 3.2\\\\_MetabolicSetTheory_repo\\\\_ModelsAndNetworks\\\\models\\\\Anaerofustis_stercorihominis_DSM_17244.xml',\n",
       " 'c:\\\\Users\\\\sainz\\\\OneDrive\\\\Desktop\\\\Hamburg 3.2\\\\_MetabolicSetTheory_repo\\\\_ModelsAndNetworks\\\\models\\\\Anaerostipes_caccae_DSM_14662.xml',\n",
       " 'c:\\\\Users\\\\sainz\\\\OneDrive\\\\Desktop\\\\Hamburg 3.2\\\\_MetabolicSetTheory_repo\\\\_ModelsAndNetworks\\\\models\\\\Anaerotruncus_colihominis_DSM_17241.xml',\n",
       " 'c:\\\\Users\\\\sainz\\\\OneDrive\\\\Desktop\\\\Hamburg 3.2\\\\_MetabolicSetTheory_repo\\\\_ModelsAndNetworks\\\\models\\\\Bacteroides_caccae_ATCC_43185.xml',\n",
       " 'c:\\\\Users\\\\sainz\\\\OneDrive\\\\Desktop\\\\Hamburg 3.2\\\\_MetabolicSetTheory_repo\\\\_ModelsAndNetworks\\\\models\\\\Bacteroides_cellulosilyticus_DSM_14838.xml',\n",
       " 'c:\\\\Users\\\\sainz\\\\OneDrive\\\\Desktop\\\\Hamburg 3.2\\\\_MetabolicSetTheory_repo\\\\_ModelsAndNetworks\\\\models\\\\Bacteroides_coprophilus_DSM_18228.xml',\n",
       " 'c:\\\\Users\\\\sainz\\\\OneDrive\\\\Desktop\\\\Hamburg 3.2\\\\_MetabolicSetTheory_repo\\\\_ModelsAndNetworks\\\\models\\\\Bacteroides_dorei_DSM_17855.xml']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = os.path.join(os.getcwd(), \"models\")\n",
    "files = natsort.natsorted(glob.glob(model_dir + '/*.xml'))\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in files:\n",
    "    model = read_sbml_model(file)\n",
    "    species = file.split('\\\\')[-1].split('.')[0]\n",
    "\n",
    "    li = []\n",
    "    for reac in model.reactions:\n",
    "        li.append(reac.reaction)\n",
    "\n",
    "    li_id = []\n",
    "    for reac in model.reactions:\n",
    "        li_id.append(reac.id)\n",
    "\n",
    "    # Export possible exchange substances\n",
    "    ex_index = [i for i in range(len(li_id)) if 'EX_' in li_id[i]]\n",
    "    possdf = pd.DataFrame([li[i].split(' <=>')[0] for i in ex_index], columns= ['PossibleSubstance'])\n",
    "    possdf.to_csv(f'possible_substances_{species}.txt', index=None)\n",
    "\n",
    "    # Export bimass reaction\n",
    "    biomass_index = [i for i in range(len(li_id)) if li_id[i] == f'{[j for j in li_id if \"biomass\" in j][-1]}']\n",
    "    biomass_react = li[biomass_index[0]].split( ' --> ')[0]\n",
    "    biomass_reactants = [i.split(' ')[-1] for i in biomass_react.split(' + ')]\n",
    "    biomass_prod = li[biomass_index[0]].split(' --> ')[1]\n",
    "    biomass_products = [i.split(' ')[-1] for i in biomass_prod.split(' + ')]\n",
    "    forward_biomass_reaction = (biomass_reactants, biomass_products)\n",
    "\n",
    "    with open(f'{species}_biomassReaction.txt', 'w') as outfile:\n",
    "        outfile.write('\\n'.join(str(i) for i in forward_biomass_reaction))\n",
    "\n",
    "    # Segregate all reactions\n",
    "    forwardreactions_index = [i for i in range(len(li)) if '-->' in li[i]]\n",
    "    backwardreactions_index = [i for i in range(len(li)) if '<--' in li[i]]\n",
    "    reversiblereactions_index = [i for i in range(len(li)) if '<=>' in li[i]]\n",
    "\n",
    "    forwardreactions = [li[i] for i in range(len(li)) if i in forwardreactions_index]\n",
    "    backwardreactions = [li[i] for i in range(len(li)) if i in backwardreactions_index]\n",
    "    reversiblereactions = [li[i] for i in range(len(li)) if i in reversiblereactions_index]\n",
    "\n",
    "    # Filter forward reactions\n",
    "    legit_forwardreactions = [i.split(' --> ') for i in forwardreactions]\n",
    "    legit_forwardreactions = [i for i in legit_forwardreactions if ((len(i[0].replace(' ', '')) > 0)&(len(i[1].replace(' ', '')) > 0))]\n",
    "    \n",
    "    for_reactants = [[item for item in i[0].split(' ') if ((item.replace('.','',1).isdigit() == False) & (item != '+'))] for i in legit_forwardreactions]\n",
    "    for_products = [[item for item in i[1].split(' ') if ((item.replace('.','',1).isdigit() == False) & (item != '+'))] for i in legit_forwardreactions]\n",
    "    \n",
    "    forwards = list(zip(for_reactants, for_products))\n",
    "\n",
    "    # Filter backward reactions\n",
    "    legit_backwardreactions = [i.split(' <-- ') for i in backwardreactions]\n",
    "    legit_backwardreactions = [i for i in legit_backwardreactions if ((len(i[0].replace(' ', '')) > 0)&(len(i[1].replace(' ', '')) > 0))]\n",
    "    \n",
    "    back_reactants = [[item for item in i[1].split(' ') if ((item.replace('.','',1).isdigit() == False) & (item != '+'))] for i in legit_backwardreactions]\n",
    "    back_products = [[item for item in i[0].split(' ') if ((item.replace('.','',1).isdigit() == False) & (item != '+'))] for i in legit_backwardreactions]\n",
    "    \n",
    "    backwards = list(zip(back_reactants, back_products))\n",
    "\n",
    "    # Filter reversible forward-backward reactions\n",
    "    legit_reversiblereactions = [i.split(' <=> ') for i in reversiblereactions]\n",
    "    legit_reversiblereactions = [i for i in legit_reversiblereactions if ((len(i[0].replace(' ', '')) > 0)&(len(i[1].replace(' ', '')) > 0))]\n",
    "\n",
    "    rev_for_reactants = [[item for item in i[0].split(' ') if ((item.replace('.','',1).isdigit() == False) & (item != '+'))] for i in legit_reversiblereactions]\n",
    "    rev_for_products = [[item for item in i[1].split(' ') if ((item.replace('.','',1).isdigit() == False) & (item != '+'))] for i in legit_reversiblereactions]\n",
    "\n",
    "    rev_forwards = list(zip(rev_for_reactants, rev_for_products))\n",
    "    rev_backwards = list(zip(rev_for_products, rev_for_reactants))\n",
    "    \n",
    "    # Combine all reactions\n",
    "    all_reactions = forwards + backwards + rev_forwards + rev_backwards\n",
    "\n",
    "    # Convert reactions to edges\n",
    "    react_edge = [[[(item[0][i],item[1][j]) for j in range(len(item[1]))] for i in range(len(item[0]))] for item in all_reactions]\n",
    "    react_edge__ = [item for sublist in react_edge for item in sublist]\n",
    "    edges = [item for sublist in react_edge__ for item in sublist]\n",
    "\n",
    "    edgelist = list(set(edges))\n",
    "    nodelist = list(set([item for sublist in edgelist for item in sublist]))\n",
    "\n",
    "    # Create and export networkX graph\n",
    "    graph = nx.from_edgelist(edgelist, create_using= nx.DiGraph())\n",
    "    pd_adj = nx.to_pandas_adjacency(graph)\n",
    "    pd_adj.to_csv(f'{species}_Adjacency.csv')\n",
    "\n",
    "    # Export cleaned edgelist\n",
    "    B_edgelist = [[j.replace('[', '_').replace(']', '') for j in i] for i in edgelist]\n",
    "    pd.DataFrame(B_edgelist).to_csv(f'{species}_Edgelist.txt', header = None, index = None, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microbiomE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
